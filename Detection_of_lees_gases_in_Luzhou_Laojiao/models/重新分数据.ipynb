{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cd37d7-9ef6-4050-8412-62b32bb86c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d12c7a3-cd01-4144-9d90-f4aecfe7ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masked_dataset():\n",
    "\n",
    "    \"\"\"\n",
    "    生成 masked dataset,\n",
    "    我们输入的原始光谱是 (number_data, seq_len), 其中seq len就是光谱向量的长度\n",
    "    我们目前考虑在完整的长度为3321个sampling points组成的2950~3150的光谱范围内\n",
    "    随机选择两个端点， 截取端点内的光谱，作为训练数据，\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def generate_mask1(self, selected_window_length, total_sequence_length):\n",
    "        \n",
    "        assert selected_window_length < total_sequence_length, \"the selected window length should be lower than the total sequence length\"\n",
    "        mask = np.zeros(total_sequence_length)\n",
    "         \n",
    "        start_point = np.random.randint(0, total_sequence_length-selected_window_length)\n",
    "        end_point = start_point + selected_window_length\n",
    "\n",
    "        mask[: selected_window_length] = 1\n",
    "        \"\"\"\n",
    "        这里的mask是一个长度为seq len的向量，因为我们目前是截取之后从头放在完整的光谱内，所以从0到截止位置，都是真实的光谱，\n",
    "        截止位置往后开始，是padding补的0，mask从这里开始全部是0，因此将来在使用mask时候，不会因为光谱本身的0而被分配一个-inf的\n",
    "        数值在计算attention的时候\n",
    "        \"\"\"\n",
    "        return mask, start_point, end_point\n",
    "    \n",
    "    def generate_mask2(self, total_sequence_length):\n",
    "        \n",
    "        mask = np.zeros(total_sequence_length)\n",
    "        \n",
    "        start_point = 0\n",
    "        end_point = 0\n",
    "        # 使用循环确保起点和终点的差大于等于 200\n",
    "        # 这里200是一个保险，太小了光谱范围太短了，而且通常也不会这么小\n",
    "        while abs(start_point - end_point) < 500 or end_point <= start_point:\n",
    "            start_point = np.random.randint(0, total_sequence_length)\n",
    "            end_point = np.random.randint(0, total_sequence_length)\n",
    "\n",
    "        mask[: end_point-start_point] = 1\n",
    "\n",
    "        return mask, start_point, end_point\n",
    "\n",
    "    def apply_mask(self, dataset, if_fixed_window_length, selected_window_length=None):\n",
    "        \n",
    "        number_data = dataset.shape[0]\n",
    "        total_data_length = dataset.shape[1]\n",
    "        checkpoints = np.zeros((number_data, 2))\n",
    "        mask_list = np.zeros((number_data, total_data_length))\n",
    "        masked_dataset = np.zeros((number_data, total_data_length))\n",
    "        \n",
    "        if if_fixed_window_length == True:\n",
    "        \n",
    "            for i in range(number_data):\n",
    "                mask, start, end = self.generate_mask1(selected_window_length, total_data_length)\n",
    "                mask_list[i] = mask\n",
    "                masked_dataset[i, :end-start] = dataset[i, start: end]\n",
    "                checkpoints[i, 0] = start\n",
    "                checkpoints[i, 1] = end\n",
    "        else:\n",
    "            for i in range(number_data):\n",
    "                mask, start, end = self.generate_mask2(total_data_length)\n",
    "                mask_list[i] = mask\n",
    "                masked_dataset[i, :end-start] = dataset[i, start: end]\n",
    "                checkpoints[i, 0] = start\n",
    "                checkpoints[i, 1] = end\n",
    "        \"\"\"\n",
    "        mask list就是所有的mask\n",
    "        chekcpoint记录了在原施光谱中截取的端点的索引，有了这个，将来可以通过checkpoints对应到Nu上了\n",
    "        self.dataset 就是保存截取之后，并且被padding 0 了的新的数据集，每一行是一个截取的光谱，并且label与原施数据集的label对应\n",
    "\n",
    "        \"\"\"\n",
    "        return mask_list, checkpoints, masked_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1411c8-f1e9-45a5-834d-e9131f3519dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\科研项目\\多组分气体识别与浓度检测\\数据集\\HITRAN_dataset\\实验\\甲烷、丙酮、水数据库\\数据集\\混合气体吸收光谱\\input.npy\"\n",
    "label_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\科研项目\\多组分气体识别与浓度检测\\数据集\\HITRAN_dataset\\实验\\甲烷、丙酮、水数据库\\数据集\\混合气体吸收光谱\\label.npy\"\n",
    "nu_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\科研项目\\多组分气体识别与浓度检测\\数据集\\HITRAN_dataset\\实验\\甲烷、丙酮、水数据库\\数据集\\原始数据\\波数.npy\"\n",
    "\n",
    "blended_spectra = np.load(input_path)  # (10150, 3321)\n",
    "label = np.load(label_path)   #  (10150, 6)\n",
    "nu = np.load(nu_path)  # (3321,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ba4b78c-9b69-4e48-8a61-81337a8993d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_time = 10\n",
    "\n",
    "maskset = np.zeros((1, blended_spectra.shape[1]))\n",
    "spectraset = np.zeros((1, blended_spectra.shape[1]))\n",
    "checkpointset = np.zeros((1, 2))\n",
    "masking = Masked_dataset()\n",
    "\n",
    "for i in range(repeat_time):\n",
    "    \n",
    "    generated_masks, checkpoint_list, masked_dataset = masking.apply_mask(blended_spectra, False)\n",
    "    # print(checkpoint_list.shape)\n",
    "\n",
    "    spectraset = np.vstack((spectraset, masked_dataset))\n",
    "\n",
    "    maskset = np.vstack((maskset, generated_masks))\n",
    "\n",
    "    checkpointset = np.vstack((checkpointset, checkpoint_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ed7d9a-98dd-474d-afa7-163f4487d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101500, 3321)\n",
      "(101500, 3321)\n",
      "(101500, 2)\n"
     ]
    }
   ],
   "source": [
    "spectraset = spectraset[1:]\n",
    "maskset = maskset[1:]\n",
    "checkpointset = checkpointset[1:]\n",
    "\n",
    "print(spectraset.shape)\n",
    "print(maskset.shape)\n",
    "print(checkpointset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7868e2b0-27d3-44b2-8bad-6fc5772b1eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101500, 6)\n"
     ]
    }
   ],
   "source": [
    "label_shape = label.shape[1]  # (6)\n",
    "label = label[np.newaxis, :, :]  # [1, 10150, 6]\n",
    "label = np.repeat(label, repeat_time, 0)  # [10, 10150, 6]\n",
    "new_label = label.reshape(-1, label_shape)   # [10150* repeat_time, 6]\n",
    "print(new_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8ae86ac-ae04-4bde-84f1-cf6e4c70deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label[:, 3:5] = new_label[:, 3:5] / 50\n",
    "new_label[:, 5] = new_label[:, 5] / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8730b884-261c-4af5-9ce1-73ed2c0f77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"D:\\PYHTON\\python3.7\\DeepLearningProgram\\科研项目\\Detection_of_lees_gases_in_Luzhou_Laojiao\\Datasets\\三组分气体生成的数据集\\模拟数据集\"\n",
    "\n",
    "save_path1 = root_path + r\"\\padded_dataset.npy\"\n",
    "np.save(save_path1, spectraset)\n",
    "\n",
    "save_path2 = root_path + r\"\\masked_dataset_label.npy\"\n",
    "np.save(save_path2, new_label)\n",
    "\n",
    "nu_path = root_path + r\"\\nu.npy\"\n",
    "np.save(nu_path, nu)\n",
    "\n",
    "mask_path = root_path + r\"\\mask.npy\"\n",
    "np.save(mask_path, maskset)\n",
    "\n",
    "checkpoints_path = root_path + r\"\\checkpoints.npy\"\n",
    "np.save(checkpoints_path, checkpointset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34ca69-e5bc-4bda-adba-cd3f639d54da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
