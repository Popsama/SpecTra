{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0e725f5-be5f-4b77-a55b-991c37bafa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a056f52-b2b7-45b0-9aff-017682a959ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_data, labels, input_masks):\n",
    "        self.input_data = input_data\n",
    "        self.labels = labels\n",
    "        self.input_masks = input_masks\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_item = self.input_data[idx]\n",
    "        label_item = self.labels[idx]\n",
    "        mask_item = self.input_masks[idx]\n",
    "\n",
    "        return input_item, label_item, mask_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7819aac7-9d17-4e37-8a5a-2e9a727fe4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tensor(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = tensor.type(torch.cuda.FloatTensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77445b2e-f1e8-43f5-8552-906ee4104ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, attention_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(input_size, attention_size)\n",
    "        self.v = nn.Linear(attention_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, src, src_mask):\n",
    "        \n",
    "        # src = (batch, seq_len, input_size) input_size = 1\n",
    "        # src_mask = (batch, seq_len)\n",
    "        \n",
    "        # energy = (batch, seq_len, attention_size)\n",
    "        energy = torch.tanh(self.attn(src))\n",
    "        \n",
    "        # attention = (batch, seq_len, 1)\n",
    "        # attention = (batch, seq_len)\n",
    "        energy = self.v(energy).squeeze()\n",
    "        \n",
    "        energy = energy.masked_fill(src_mask == 0, -1e10)\n",
    "     \n",
    "        # (batch, seq_len, 1)\n",
    "        attention_weights = F.softmax(energy, dim=1)\n",
    "        \n",
    "        # (batch, seq_len, 1)\n",
    "        attention_weights = attention_weights.unsqueeze(2)\n",
    "       \n",
    "     \n",
    "        context = attention_weights * src\n",
    "        # context = (batch, seq_len, input_size)\n",
    "        \n",
    "        # return weights\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d653f-bf44-4b7e-bccc-8b222d4854b0",
   "metadata": {},
   "source": [
    "### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2eaa4c-8a98-470b-8eb1-9971a99288ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3321\n",
    "half_length = sequence_length // 2\n",
    "num_masks = 10\n",
    "x_mask = [torch.cat((torch.ones(half_length), torch.zeros(sequence_length - half_length))) for _ in range(num_masks)]\n",
    "x_mask = torch.stack(x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2abe2be1-b52b-4f79-bf7d-ed096be3d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3321])\n"
     ]
    }
   ],
   "source": [
    "print(x_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56c3e3fe-f2c4-4645-96f9-adc6ac34dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3321, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3321, 1)\n",
    "attention_layer = Attention(1, 128)\n",
    "x, attention_weights = attention_layer(x, x_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83bd91e0-b357-41b4-9fb2-bf4fafa5b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3321, 1])\n",
      "torch.Size([10, 3321, 1])\n",
      "tensor([[0.0007, 0.0005, 0.0005,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0007, 0.0006, 0.0006,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0007, 0.0004, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0006, 0.0006, 0.0004,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0003, 0.0004, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0006, 0.0006, 0.0007,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "tensor([[-0.0002],\n",
      "        [ 0.0003],\n",
      "        [ 0.0003],\n",
      "        ...,\n",
      "        [ 0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(attention_weights.shape)\n",
    "print(attention_weights.squeeze())\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c96a2ec-6219-47a3-8783-0db2963ff74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x = [batch size, seq len, input_dim]\n",
    "        \n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        # x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        # x = [batch size, seq len, input_dim]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740996fe-0d47-4361-b09f-f6b13a71f3e2",
   "metadata": {},
   "source": [
    "### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec5c6568-c410-40e4-a64e-dc146dc2f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3321, 1])\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "x = torch.randn(10, 3321, 1)\n",
    "attention_layer = Attention(1, 128)\n",
    "x, attention_weights = attention_layer(x, x_mask)\n",
    "\n",
    "print(x.shape)\n",
    "print(attention_weights.shape)\n",
    "\n",
    "######################################################\n",
    "pf_layer = PositionwiseFeedforwardLayer(1, 64, 0.1)\n",
    "x = pf_layer(x)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57680790-c897-41ee-a95f-55936431e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 attention_size,\n",
    "                 pf_dim,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(input_size)\n",
    "        self.ff_layer_norm = nn.LayerNorm(input_size)\n",
    "        self.self_attention = Attention(input_size, attention_size)\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(input_size,\n",
    "                                                                     pf_dim,\n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src = [batch size, src_len, input_dim]\n",
    "        # src_mask = [batch size, src len]\n",
    "\n",
    "        # self attention\n",
    "        _src, _ = self.self_attention(src, src_mask)\n",
    "    \n",
    "        # src = [batch, seq_len, input_dim]\n",
    "\n",
    "        # dropout, residual connection and layer norm\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # src = [batch size, src len, hid dim]\n",
    "\n",
    "        # positionwise feedforward\n",
    "        _src = self.positionwise_feedforward(src)\n",
    "\n",
    "        # dropout, residual and layer norm\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # src = [batch size, src len, hid dim]\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34092224-4fed-4ffa-a26d-d6f4edceb746",
   "metadata": {},
   "source": [
    "### 测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bdebbb1-2d3d-43f8-8cb4-7dcc7b4f19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_mask is in shape of torch.Size([10, 3321]) \n",
      "x is in shape of torch.Size([10, 3321, 32]) \n",
      "torch.Size([10, 3321, 32])\n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "attention_size = 128\n",
    "pd_dim = 64\n",
    "dropout = 0.1\n",
    "#####################################################\n",
    "# mask \n",
    "sequence_length = 3321\n",
    "half_length = sequence_length // 2\n",
    "num_masks = 10\n",
    "x_mask = [torch.cat((torch.ones(half_length), torch.zeros(sequence_length - half_length))) for _ in range(num_masks)]\n",
    "x_mask = torch.stack(x_mask)\n",
    "print(\"x_mask is in shape of {} \".format(x_mask.shape))\n",
    "######################################################\n",
    "# src\n",
    "x = torch.randn(10, 3321, input_size)\n",
    "\n",
    "print(\"x is in shape of {} \".format(x.shape))\n",
    "######################################################\n",
    "# encoder layer\n",
    "enc_layer = EncoderLayer(input_size, attention_size, pd_dim, dropout)\n",
    "x = enc_layer(x, x_mask)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb79f25-f69d-49b4-9e8f-6265a0333830",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee93e61-44ec-414f-aba6-c321abdade0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # 目前先用一层的encoder试试\n",
    "    \n",
    "    def __init__(self, encoderrnn, attention):\n",
    "        super().__init__()\n",
    "        self.encoderrnn = encoderrnn\n",
    "        self.attention = attention\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, x, hidden = encoderrnn(x)\n",
    "        hidden = hidden.squeeze()\n",
    "        context = self.attention(output, x)\n",
    "        concatenation = torch.cat((context, hidden), dim=1)\n",
    "        \n",
    "        return concatenation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
